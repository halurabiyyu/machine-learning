{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.7-py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\halur\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\halur\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (8.1.7)\n",
      "Collecting dm-tree (from tensorflow_datasets)\n",
      "  Downloading dm_tree-0.1.8-cp312-cp312-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting immutabledict (from tensorflow_datasets)\n",
      "  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\halur\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.26.4)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\halur\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\halur\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\halur\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (14.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\halur\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.32.2)\n",
      "Collecting simple-parsing (from tensorflow_datasets)\n",
      "  Downloading simple_parsing-0.1.6-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Downloading tensorflow_metadata-1.16.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\halur\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.5.0)\n",
      "Requirement already satisfied: toml in c:\\users\\halur\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\halur\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.66.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\halur\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.14.1)\n",
      "Collecting etils>=1.9.1 (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets)\n",
      "  Downloading etils-1.10.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\halur\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (2024.3.1)\n",
      "Collecting importlib_resources (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\halur\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (4.11.0)\n",
      "Requirement already satisfied: zipp in c:\\users\\halur\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\halur\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\halur\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\halur\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\halur\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\halur\\anaconda3\\lib\\site-packages (from click->tensorflow_datasets) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\halur\\anaconda3\\lib\\site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from simple-parsing->tensorflow_datasets)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.56.4 (from tensorflow-metadata->tensorflow_datasets)\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf>=3.20 (from tensorflow_datasets)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Downloading tensorflow_datasets-4.9.7-py3-none-any.whl (5.3 MB)\n",
      "   ---------------------------------------- 0.0/5.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/5.3 MB 2.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.3/5.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.7/5.3 MB 5.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.3/5.3 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.8/5.3 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.4/5.3 MB 9.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.1/5.3 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.4/5.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.9/5.3 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.6/5.3 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.9/5.3 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.3/5.3 MB 10.0 MB/s eta 0:00:00\n",
      "Downloading etils-1.10.0-py3-none-any.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 164.9/164.9 kB ? eta 0:00:00\n",
      "Downloading dm_tree-0.1.8-cp312-cp312-win_amd64.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.8/101.8 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading simple_parsing-0.1.6-py3-none-any.whl (112 kB)\n",
      "   ---------------------------------------- 0.0/112.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 112.6/112.6 kB 6.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow_metadata-1.16.1-py3-none-any.whl (28 kB)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 431.5/431.5 kB 13.6 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "   ---------------------------------------- 0.0/220.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 220.9/220.9 kB 13.2 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21544 sha256=01cbd550e0a2c8c324154b2b484e8642f79629435c1c3acad007ed48bcfbce23\n",
      "  Stored in directory: c:\\users\\halur\\appdata\\local\\pip\\cache\\wheels\\e7\\e6\\28\\864bdfee5339dbd6ddcb5a186286a8e217648ec198bdf0097d\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, protobuf, promise, importlib_resources, immutabledict, etils, docstring-parser, simple-parsing, googleapis-common-protos, tensorflow-metadata, tensorflow_datasets\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "Successfully installed dm-tree-0.1.8 docstring-parser-0.16 etils-1.10.0 googleapis-common-protos-1.65.0 immutabledict-4.2.0 importlib_resources-6.4.5 promise-2.3 protobuf-5.28.3 simple-parsing-0.1.6 tensorflow-metadata-1.16.1 tensorflow_datasets-4.9.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.32.0 requires protobuf<5,>=3.20, but you have protobuf 5.28.3 which is incompatible.\n",
      "tensorflow-intel 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\halur\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\u001b[0m\n",
      "\u001b[1mDataset imdb_reviews downloaded and prepared to C:\\Users\\halur\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
      "label:  0\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "  print('text: ', example.numpy())\n",
    "  print('label: ', label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [b'I\\'ll be honest. I got this movie so I could make fun of it. I mean, come on, \"Hood of the Living Dead\"? What other reaction could I have? The thing is, though, the movie (and its makers) decided that it wasn\\'t going to be made fun of. Instead, it was going to try its best to be a good movie.<br /><br />And you know what? It came awfully close. A little less cheese in the incidental music, a little more professionalism in the photography, the acting, the incidentals (like the props--love the Best Buy bag)...well, it\\'s not a classic of the zombie movie genre, but it\\'s still a pretty neat little movie on its own. And the acting, writing and pacing are all surprisingly better than I would have expected. There\\'s even some decent humor, as two of our leads debate how to decide if a dead zombie is really dead.<br /><br />If you can overlook the low budget (which leaves its fingerprints in everything, alas) and the almost constant profanity, this can be a pretty fun time at the movies. No, it ain\\'t great. Yes, it could have been better. But the makers, the actors, the crew, they all tried to make a good film (instead of a camp classic) and that counts for a lot. The line of campy zombie films is a mile long, and thank you, guys, for not adding to it.<br /><br />Kudos to the Quiroz brothers. I\\'d love to see what they do next. And hey, somebody, give them a budget!'\n",
      " b\"Just a note to add to the above comment. Fear of a Black Hat doesn't have the criminal who's image has been ripped off by the band, that's in CB4. Easily confused as the two films are so similar, but Black Hat is vastly the superior of the two..... yeah.\"\n",
      " b\"A kid with ideals who tries to change things around him. A boy who is forced to become a man, because of the system. A system who hides the truth, and who is violating the rights of existence. A boy who, inspired by Martin Luther King, stands up, and tells the truth. A family who is falling apart, and fighting against it. A movie you can't hide from. You see things, and you hear things, and you feel things, that you till the day you die will hope have never happened for real. Violence, frustration, abuse of power, parents who can't do anything, and a boy with, I am sorry, balls, a boy who will not accept things, who will not let anything happen to him, a kid with power, and a kid who acts like a pro, like he has never done anything else, he caries this movie to the end, and anyone who wants to see how abuse found place back in the 60'ies.\"]\n",
      "\n",
      "labels:  [1 1 1]\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for example, label in train_dataset.take(1):\n",
    "  print('texts: ', example.numpy()[:3])\n",
    "  print()\n",
    "  print('labels: ', label.numpy()[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
       "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[527,  28,   1, ...,   0,   0,   0],\n",
       "       [ 41,   4, 878, ...,   0,   0,   0],\n",
       "       [  4, 548,  17, ...,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_example=encoder(example)[:3].numpy()\n",
    "encoded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  b'I\\'ll be honest. I got this movie so I could make fun of it. I mean, come on, \"Hood of the Living Dead\"? What other reaction could I have? The thing is, though, the movie (and its makers) decided that it wasn\\'t going to be made fun of. Instead, it was going to try its best to be a good movie.<br /><br />And you know what? It came awfully close. A little less cheese in the incidental music, a little more professionalism in the photography, the acting, the incidentals (like the props--love the Best Buy bag)...well, it\\'s not a classic of the zombie movie genre, but it\\'s still a pretty neat little movie on its own. And the acting, writing and pacing are all surprisingly better than I would have expected. There\\'s even some decent humor, as two of our leads debate how to decide if a dead zombie is really dead.<br /><br />If you can overlook the low budget (which leaves its fingerprints in everything, alas) and the almost constant profanity, this can be a pretty fun time at the movies. No, it ain\\'t great. Yes, it could have been better. But the makers, the actors, the crew, they all tried to make a good film (instead of a camp classic) and that counts for a lot. The line of campy zombie films is a mile long, and thank you, guys, for not adding to it.<br /><br />Kudos to the Quiroz brothers. I\\'d love to see what they do next. And hey, somebody, give them a budget!'\n",
      "Round-trip:  ill be [UNK] i got this movie so i could make fun of it i mean come on [UNK] of the living dead what other [UNK] could i have the thing is though the movie and its [UNK] decided that it wasnt going to be made fun of instead it was going to try its best to be a good moviebr br and you know what it came [UNK] close a little less [UNK] in the [UNK] music a little more [UNK] in the [UNK] the acting the [UNK] like the [UNK] the best buy [UNK] its not a classic of the zombie movie genre but its still a pretty [UNK] little movie on its own and the acting writing and [UNK] are all [UNK] better than i would have expected theres even some decent humor as two of our leads [UNK] how to [UNK] if a dead zombie is really [UNK] br if you can [UNK] the low budget which leaves its [UNK] in everything [UNK] and the almost [UNK] [UNK] this can be a pretty fun time at the movies no it [UNK] great yes it could have been better but the [UNK] the actors the [UNK] they all tried to make a good film instead of a [UNK] classic and that [UNK] for a lot the line of [UNK] zombie films is a [UNK] long and [UNK] you guys for not [UNK] to itbr br [UNK] to the [UNK] brothers id love to see what they do next and [UNK] [UNK] give them a budget                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      "\n",
      "Original:  b\"Just a note to add to the above comment. Fear of a Black Hat doesn't have the criminal who's image has been ripped off by the band, that's in CB4. Easily confused as the two films are so similar, but Black Hat is vastly the superior of the two..... yeah.\"\n",
      "Round-trip:  just a note to add to the above comment [UNK] of a black [UNK] doesnt have the [UNK] whos [UNK] has been [UNK] off by the [UNK] thats in [UNK] easily [UNK] as the two films are so similar but black [UNK] is [UNK] the [UNK] of the two [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      "\n",
      "Original:  b\"A kid with ideals who tries to change things around him. A boy who is forced to become a man, because of the system. A system who hides the truth, and who is violating the rights of existence. A boy who, inspired by Martin Luther King, stands up, and tells the truth. A family who is falling apart, and fighting against it. A movie you can't hide from. You see things, and you hear things, and you feel things, that you till the day you die will hope have never happened for real. Violence, frustration, abuse of power, parents who can't do anything, and a boy with, I am sorry, balls, a boy who will not accept things, who will not let anything happen to him, a kid with power, and a kid who acts like a pro, like he has never done anything else, he caries this movie to the end, and anyone who wants to see how abuse found place back in the 60'ies.\"\n",
      "Round-trip:  a kid with [UNK] who tries to change things around him a boy who is forced to become a man because of the [UNK] a [UNK] who [UNK] the truth and who is [UNK] the [UNK] of [UNK] a boy who [UNK] by [UNK] [UNK] king [UNK] up and tells the truth a family who is [UNK] apart and fighting against it a movie you cant [UNK] from you see things and you hear things and you feel things that you [UNK] the day you die will hope have never happened for real violence [UNK] [UNK] of power parents who cant do anything and a boy with i am sorry [UNK] a boy who will not [UNK] things who will not let anything happen to him a kid with power and a kid who [UNK] like a [UNK] like he has never done anything else he [UNK] this movie to the end and anyone who wants to see how [UNK] found place back in the [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "  print(\"Original: \", example[n].numpy())\n",
    "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([layer.supports_masking for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: str3296",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# predict on a sample text without padding.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m sample_text \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe movie was cool. The animation and the graphics\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwere out of this world. I would recommend this movie.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([sample_text]))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\halur\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\halur\\anaconda3\\Lib\\site-packages\\optree\\ops.py:747\u001b[0m, in \u001b[0;36mtree_map\u001b[1;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[0;32m    745\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[0;32m    746\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[1;32m--> 747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treespec\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;28mmap\u001b[39m(func, \u001b[38;5;241m*\u001b[39mflat_args))\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid dtype: str3296"
     ]
    }
   ],
   "source": [
    "# predict on a sample text without padding.\n",
    "\n",
    "sample_text = ('The movie was cool. The animation and the graphics'\n",
    "               'were out of this world. I would recommend this movie.')\n",
    "\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: str256000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# predict on a sample text with padding\u001b[39;00m\n\u001b[0;32m      3\u001b[0m padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m----> 4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([sample_text, padding]))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\halur\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\halur\\anaconda3\\Lib\\site-packages\\optree\\ops.py:747\u001b[0m, in \u001b[0;36mtree_map\u001b[1;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[0;32m    745\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[0;32m    746\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[1;32m--> 747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treespec\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;28mmap\u001b[39m(func, \u001b[38;5;241m*\u001b[39mflat_args))\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid dtype: str256000"
     ]
    }
   ],
   "source": [
    "# predict on a sample text with padding\n",
    "\n",
    "padding = \"the \" * 2000\n",
    "predictions = model.predict(np.array([sample_text, padding]))\n",
    "print(predictions[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
